{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titre\n",
    "\n",
    "Enoncé du problème et objectif général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabien/.local/lib/python3.8/site-packages/geopandas/_compat.py:84: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import pylab as plt, seaborn as sns\n",
    "import geopandas as gpd, networkx as nx\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn import preprocessing as skpp\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#pd.set_option('display.max_row', 300)\n",
    "#pd.set_option('display.max_column', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Collection\n",
    "\n",
    "Link INSEE, France Data, Kaggle Dataset, WebScrapling, Yahoo Finance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-a. Data knowledge\n",
    "\n",
    "Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-b. Data overview\n",
    "\n",
    "- Spreadsheet vizualization\n",
    "- Variable list (scale, dependency, type)\n",
    "- Objectif mesurable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-c. Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.read_csv(os.getcwd() + '/file.csv')\n",
    "dataf = pd.read_excel('path.excel', sheet_name=['name'])\n",
    "geodf = gpd.read_file(\"path.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic statistic\n",
    "data.describes() # all\n",
    "print(dataf['columns'].sum())\n",
    "dataf.groupby(['columns1','columns2']).agg(['mean','std']) # pivot table of specifics feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-d. Data pre-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new feature\n",
    "dataf['new_columns'] = dataf['columns A'] / dataf['columns B']\n",
    "dataf.insert(1, 'new_columns', dataf[['A','B']].idxmax(1)) # feature 2 labels variables\n",
    "## specifics visualization\n",
    "geodf = geodf.merge(dataf[['ON', 'new']], how='inner', on='ON')\n",
    "geo_df[geo_df.ON.str[:2] != \"97\"].plot(ax = ax, categorical=True, column = \"Results\", legend=True)\n",
    "#### simplify dataset (bonus : scipy.interpolate)\n",
    "data = data.drop(columns=columns_list)\n",
    "\"\"\" you can create columns by group \"Missing indicator\" if empty info (ex : confidential data), it's becaume data information \"\"\"\n",
    "# interpolate data & verification\n",
    "data = (data1['var_list'] + data2['var_list']) / 2 # good order (simplify data)\n",
    "sns.catplot(data = pd.concat([data1['specVar'],data['specVar'],data2['specVar']], axis=1), kind=\"violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-e. Data compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataf_list :\n",
    "    data = pd.merge(data, d, how='inner', on='ON') # automatics also with time series\n",
    "# head or tail\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Find interesting variables for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-a. Data definition\n",
    "\n",
    "Variable target :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) # row and columns\n",
    "print(df.dtypes.value_counts()) # variable type\n",
    "print((df.isna().sum()/df.shape[0]).sort_values(ascending=True)) # NaN proportion\n",
    "# for time series : see resample per date, rolling/ewn, FFT analysis (+possible filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-b. Data relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.select_dtypes('float').corr()\n",
    "grid = sns.clustermap(corr) # correlation map linked by average method and euclidean metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete relation ship (max columns = 20, sample dataset by 1000)\n",
    "sns.pairplot(df.sample(1000), hue=\"label\") # histogram and all variable/variable scatter\n",
    "#sns.jointplot() # 2d histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-c. Data reduction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "x = df.loc[:, features].values\n",
    "x = preprocessing.StandardScaler().fit_transform(x)\n",
    "# PCA compression of continious variables (if unlinear : Manifold : IsoMap)\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "pc_df = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2', 'PC3'])\n",
    "# adding category\n",
    "pc_df['cat'] = df['label'].astype(\"category\")\n",
    "# 3D plot (contourf possible)\n",
    "#ax = plt.axes(projection='3d')\n",
    "#ax.scatter(pc_df['A'], pc_df['B'], pc_df['C'], c= pc_df['cat'])\n",
    "sns.scatterplot(data = pc_df, hue = \"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-c. Data contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigency = pd.crosstab(df['label_A'], df['label_B'])\n",
    "sns.heatmap(contigency, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-d. Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of independence\n",
    "c, p, dof, expected = chi2_contingency(contigency) \n",
    "# H0 hypothesis (student)\n",
    "stat, p = ttest_ind(df_rowsA['columns'].dropna(), df_rowsB['columns'].dropna())\n",
    "# show variable\n",
    "print(f'{'' :-<50} {if p < 0.02 : 'H0 Rejetée'}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing\n",
    "\n",
    "Prepare data for analysis and modelization (sous ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.copy()\n",
    "df_ = df[df.isna().sum()/df.shape[0] < 0.85] # only columns with no relation, completly empty or no variance (constance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-a. Dataset training-test construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(df_, test_size=0.2, random_state=0)\n",
    "# proportion of class repartition (try to distribute with the same proportion)\n",
    "trainset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-b. Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to values (possible use \"Transformer\" LabelEncoder or onehot+sparseMatrix if normalization class)\n",
    "code = {'A':0,'B':1,'C':0}\n",
    "df.loc[:,'Label'] = df[col].map(code) # lambda function also possible, otherwithe replace(list,list) or .astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*Return here after basic test modelization (Trial and error method)*\n",
    "\n",
    "### 3-c. Data Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    ### feature engineering (underfitting)\n",
    "    df['new'] = df[] # ex : polynomial feature \"optimize/extraction\", binarizer, kernel log/log. Oversampling :\n",
    "    # unsupervised_info = Kmean clustering class (+Elbow method for good seeder), PCA axis, Isolation Forest (Anomaly)\n",
    "    ### feature imputation (overfitting) - SimpleImputer(strategy='')\n",
    "    df = df.dropna() # drop-fill-NA, KNNImputer, image morphology (artefact delete). feature selection :\n",
    "    # selector = VarianceThreshold() # constante columns, other : selectKbest (Khi-2), SelectFromModel (if parameter model, KNN not included)\n",
    "    # input / target\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data modelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing(trainset)\n",
    "X_test, y_test = preprocessing(testset)\n",
    "# if not dataframe (numpy array), add shape if (N,) to be (1,N) : reshape or [None]\n",
    "# warning of numpy broadcoasting if numpy : (1,3) + (3,1) = (3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-a. Basic model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalutation(model) :\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    # first evaluation\n",
    "    #model.score(X,y) #R2 automatics metric if regression\n",
    "    # predict\n",
    "    ypred = model.predict(X_test)\n",
    "    # evaluation\n",
    "    print(confusion_matrix(y_test, ypred)) #(sum=support) nb_success A, nb_error A ## nb_succes B, nb_error B\n",
    "    print(classification_report(y_test, ypred))\n",
    "    # learning and validation curve (with cross validation : Kfold per default)\n",
    "    N, train_score, val_score = learning_curve(model, X_train, y_train,cv=4, scoring='f1',train_sizes=np.linspace(0.1, 1, 10))\n",
    "    # learning curve F1 = precision/recall (see overfit, underfit)\n",
    "    plt.plot(N, train_score.mean(axis=1), label='train score')\n",
    "    plt.plot(N, val_score.mean(axis=1), label='validation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "test_model = DecisionTreeClassifier(random_state=0) # first\n",
    "#test_model = RandomForestClassifier(random_state=0) # regularized model (basic ensemble)\n",
    "#test_model = make_pipeline(PolynomialFeatures(2), SelectKBest(f_classif, k=10), RandomForestClassifier(random_state=0)) # here contain data transform included in model\n",
    "# evaluation\n",
    "evalutation(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of feature importance (for selection)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_model.feature_importances_, index=X_train.columns).plot.bar(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*When the precision, recall and f1-score is > 50% (convergence of Law of large numbers), the dataset it's good*\n",
    "\n",
    "### 4-b. Pipeline ensemble learning\n",
    "\n",
    "Pipeline = Transformer+Estimator chain\n",
    "\n",
    "Ensemble learning = Law of large numbers + Competence + Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))\n",
    "#preprocessor = make_columns_selector((categorical_pipeline, ['cat1','...','catn']),(numerical_pipeline, ['v1','...','vn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification model (basic = logistic regression)\n",
    "RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\n",
    "AdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\n",
    "SVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\n",
    "KNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())\n",
    "# regression model (basic = linear regression)\n",
    "\"\"\"\n",
    "LinearRegression\n",
    "etc.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_models = {'RandomForest': RandomForest, # bagging : all in overfitting grouping result\n",
    "                  'AdaBoost' : AdaBoost, # boosting : all in underfitting grouping result\n",
    "                  'SVM': SVM,\n",
    "                  'KNN': KNN\n",
    "                 }\n",
    "\"\"\" Note : Stacking it's for predictor of predictor, VotingClassifier method for bagging/boosting without diversity \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in dict_of_models.items():\n",
    "    print(name)\n",
    "    evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model choisi :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-c. Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chosen model \n",
    "\"\"\"\"\n",
    "# 1st for grid\n",
    "hyper_params = {'svc__gamma':[1e-3, 1e-4],\n",
    "                'svc__C':[1, 10, 100, 1000, 3000]}\n",
    "\"\"\"\n",
    "hyper_params = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n",
    "                'svc__C':[1, 10, 100, 1000, 3000], \n",
    "               'pipeline__polynomialfeatures__degree':[2, 3],\n",
    "               'pipeline__selectkbest__k': range(45, 60)}\n",
    "# last it's not adapted for grid (too many parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(SVM, hyper_params, scoring='recall', cv=4) # first for some parameter\n",
    "grid = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=4, n_iter=40) # cv = crossvalidation (cutting in 4 validation set of train set here)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-d. Threshold search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, grid.best_estimator_.decision_function(X_test))\n",
    "plt.plot(threshold, precision[:-1], label='precision')\n",
    "plt.plot(threshold, recall[:-1], label='recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-e. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_final(model, X, threshold=0):\n",
    "    return model.decision_function(X) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_final(grid.best_estimator_, X_test, threshold=-1)\n",
    "# score for classification model\n",
    "f1_score(y_test, y_pred)\n",
    "recall_score(y_test, y_pred)\n",
    "# score for regression model\n",
    "\"\"\"\n",
    "mean_absolute_error(y_test, y_pred) # linear problem\n",
    "mean_squared_error(y_test, y_pred) # exponential problem\n",
    "median_absolute_error(y_test, y_pred) # if some outlier = robust (warning : high risk)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Chosen model, link between other report, good variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-a. Synthetic visualization\n",
    "\n",
    "*Relative to dataset :* geographic overview, pairplot, reduction_observation, feature_selection, evaluation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3)\n",
    "#gs = gridspec.GridSpec(ncols=2, nrows=2, figure=fig2)\n",
    "sns.regplot(x='value', y='wage', data=df_melt, ax=axs[0])\n",
    "sns.regplot(x='value', y='wage', data=df_melt, ax=axs[1])\n",
    "sns.boxplot(x='education',y='wage', data=df_melt, ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-b. Discussion\n",
    "\n",
    "Possible amelioration (if more time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
